---
title: "深入理解 http/2"
date: 
categories: http/2
tags: 
- http/2
---

> 以下内容摘自 [HTTP/2 简介](https://developers.google.com/web/fundamentals/performance/http2/?hl=zh-cn) ，要了解更多请移步 [《Web 性能权威指南》](http://shop.oreilly.com/product/0636920028048.do)（O'Reilly，作者：llya Grigorik）

近来 HTTP/2 的声音不断在国内各个技术论坛响起，说什么 HTTP/2 可以带来多少多少性能提升，到底是如何实现的呢？我们一起来分析一下。

<!-- more -->

HTTP/2 主要特性在如下三个方面：

1. 通过支持完整的请求与响应复用来减少延迟
2. 通过有效压缩 HTTP 标头字段，将协议开销降至最低
3. 增加请求优先级和服务器推送的支持

注：以上机制虽然不是全部，却是最重要的。

*说到这里，各位看官是不是已经遥想到当年升级 HTTPS的苦逼经历了？*

不必担心，HTTP/2 没有改动 HTTP 的应用语义。HTTP 方法、状态代码、URI 和标头字段等核心概念一如往常。不过，HTTP/2 修改数据格式化（分帧）以及客户端和服务器之间的传输方式。这两点统帅全局。通过新的分帧层，向我们的应用隐藏了所有的复杂性。因此所有现有应用都可以不必修改而在新协议下运行。

除非您在实现网络服务器（或自定义客户端），需要使用原始的 TCP 套接字，否则你可能注意不到任何区别：所有新的低级分帧由客户端和服务器为您完成。可观察到的唯一区别将是性能的提升和请求优先级、流控制和服务器推送等新功能的出现。

是不是很爽？😊

人家带给你这么多好处，总得知道下人家来自哪里吧？礼尚往来嘛，请看

###  SPDY 与 HTTP/2 简史
------
SPDY 是 Google 开发的一个实验性协议，于 2009 年年中发布，其主要目标是通过解决 HTTP/1.1 中广为人知的一些性能限制来减少网页的加载延迟。具体来说，这个项目设定的目标如下：
* 页面加载时间（PLT）减少 50%
* 无需网页作者改任何内容
* 将部署复杂性降至最低，无需更改网络基础设施
* 与开源社区合作开发这个新协议
* 收集真实数据，验证这个实验性协议是否有效

注：为了达到减少 50% 页面加载时间的目标，SPDY 引入了一个新的二进制分帧层，以实现请求和响应复用、优先级和标头压缩，目的是更有效的利用底层 TCP 连接。TCP 的三次握手和慢启动等带来的延时性能问题，请参阅[延迟是性能瓶颈](https://hpbn.co/primer-on-web-performance/#latency-as-a-performance-bottleneck)

首次发布后不久，Google 两位软件工程师 Mike Belshe 	和 Roberto Peon 就分享了他们对这个实验性 SPDY 协议的实现结果、文档和源代码。

> 目前为止，我们只在实验条件下测试过 SPDY 。> 最初的结果很激动人心：通过模拟的家庭网络连接下载了 25 个最流行的网站之后，我们发现性能提升特别明显，页面加载速度最高加快了 55% ，[*（Chromium 博客）*](https://blog.chromium.org/2009/11/2x-faster-web.html)

几年后的 2012 年，这个新的协议得到了 Chrome、Firefox、Opera 的支持，越来越多的大型网站（如 Google、Twitter、Facebook）和小型网站开始在其基础设施内部署 SPDY。事实上，在被行业越来越多的采用之后，SPDY 已经具备了成为标准的条件。

观察到这一趋势后，HTTP 工作组（HTTP-WG）将这一工作提上议事日程，吸取 SPDY 的经验教训，并在此基础上定制了官方“HTTP/2”标准。在拟定宣言草案、向社会征集 HTTP/2 建议并经过内部讨论之后，HTTP-WG 决定将 SPDY 规范作为新 HTTP/2 协议的基础。

接下来几年中 SPDY 和 HTTP/2 持续共同进化，SPDY 作为实验性分支，用于为 HTTP/2 标准测试新功能和建议。理论不一定适合实践（反之亦然），SPDY 提供了一个测试和评估路线，可以对要包括到 HTTP/2 标准中的每条建议进行测试和评估。最终，这个过程持续了三年，期间产生了 10 余条中间草案：

* 2012 年 3 月：征集 HTTP/2 建议
* 2012 年 11 月：第一个 HTTP/2 草案（基于 SPDY）
* 2014 年 8 月：HTTP/2 草案 17 和 HPACK 草案 12 发布
* 2014 年 8 月：工作组最后一次征集 HTTP/2 建议
* 2015 年 2 月：IESG 批准 HTTP/2 和 HPACK 草案
* 2015 年 5 月：RFC 7540 (HTTP/2) 和 RFC 7541 (HPACk) 发布

2015 年初，IESG 审阅了新的 HTTP/2 标准并批准发布。之后不久，Google Chrome 团队公布了他们为 TLS 弃用 SPDY 和 NPN  扩展的时间表：

> 与 HTTP/1.1 相比，HTTP/2 的主要变化在于性能提升。> 一些主要功能（例如复用、标头压缩、协议协商和优先级）演化自之前开放但不标准的协议 SPDY。Chrome 自 Chrome 6 就开始支持 SPDY，但由于大部分优点都集中在 HTTP/2 ˙中，是时候向 SPDY 说再见了。我们计划于 2016 年初停止对 SPDY 的支持，还会停止 TLS 的 NPN 扩展的支持，转而在 Chrome 中使用 ALPN。强烈建议服务器开发者迁移至 HTTP/2 和 ALPN。我们很高兴参与到最终催生了 HTTP/2 的开放式标准定制过程，并且考虑到整个行业在标准化和实现过程中的参与热情，我们希望对这标准的采纳越来越多。[*（Chromium 博客）*](https://blog.chromium.org/2015/02/hello-http2-goodbye-spdy.html)

SPDY 与 HTTP/2 的共同演化让服务器、浏览器和网站开发者可以在协议的定制过程中获得真实体验。因此，HTTP/2 协议自诞生之日起就成为最好并经过大量测试的标准之一。到 HTTP/2 被 IESG 批准时，已经有很多经过完全测试并且可以立即投入生产的客户端和服务器。事实上，在最终协议被批准的几周后，由于多款热门浏览器（和许多网站）都部署了完整的 HTTP/2 支持，大量用户都体会到了新协议的好处。

### 设计和技术目标

------

早期版本 HTTP 协议的设计初衷主要是实现简单：HTTP/0.9 只用一行代码就启动了万维网；HTTP/1.0 则是对流行的 HTTP/0.9 扩展的一个正式说明；HTTP/1.1 则是 IETF 的一份官方标准。因此，HTTP/0.9-1.x 只描述了现实是这么一回事：HTTP 是应用最广泛、采用最多的一个互联网应用协议。

然而，简单是以牺牲性能为代价的：HTTP/1.x 需要多个连接才能实现并发和缩短延迟，HTTP/1.x 不会压缩请求和响应标头，从而导致不必要的网络流量；HTTP/1.x 不支持有效的资源优先级，导致底层 TCP 协议利用率低下，等等。

这些限制并不是致命的，但是随着互联网应用的范围、复杂性以及在我们生活中的重要性不断增大，它们对网络开发者和用户都造成了巨大负担，而这正是 HTTP/2 致力于解决的：

> HTTP/2 通过支持标头字段压缩和在同一个连接上进行多个并发交换，让应用有效地利用网络资源，减少感知的延迟时间。具体来说，它可以对同一连接上的请求和响应消息进行交错发送并为 HTTP 标头字段使用有效编码。HTTP/2 还允许为请求设置优先级，让更重要的请求更快速地完成，从而进一步提升性能。出台的协议对网络更加友好，因为与 HTTP/1.x 相比，可以使用更少的 TCP 连接。
>
> 这意味着与其他流的竞争减小，并且连接持续时间变长，这些特性反过来提高了可用网络容量的利用率。最后，HTTP/2 还可以通过使用二进制消息分帧对消息进行更高效的处理。[*（超文本传输协议版本 2，草案 17）*](https://tools.ietf.org/html/draft-ietf-httpbis-http2-17)

### 二进制分帧层

------

HTTP/2 所有性能增强的核心在于新的二进制分帧层，它定义了如何封装 HTTP 消息并在客户端和服务器之间传输。

![图片](https://developers.google.com/web/fundamentals/performance/http2/images/binary_framing_layer01.svg?hl=zh-cn)

这里所谓的“层”，指的是位于套接字接口与应用可见的高级 HTTP API 之间一个经过优化的新编码机制：HTTP 的语义（包括各种动词、方法、标头）都不受影响，不同的是传输期间对它们的编码方式变了。HTTP/1.x 以换行符作为纯文本的分隔符，而 HTTP/2 将所有传输的消息分割为更小的消息和帧，并采用二进制格式对它们编码。

这样一来，客户端和服务器为了互相理解，都必须使用新的二进制编码机制：HTTP/1.x 客户端无法理解只支持 HTTP/2 的服务器，反之亦然。不过不要紧，现有的应用不必担心这些变化，因为客户端和服务器都会替我们完成必要的分帧工作。

### 数据流、消息和帧

------

新的二进制机制改变了客户端和服务器之间交换数据的方式。为了说明这个过程，我们需要了解 HTTP/2 的三个概念：

* 数据流：已建立的连接内的双向字节流，可以承载一条或多条信息
* 消息：与逻辑请求或响应消息对应的完整的一系列帧
* 帧：HTTP/2 通信的最小单位，每个帧都包括帧头，至少也会标识出当前帧所属的数据流。

这些概念的关系总结如下：

* 所有通信都在一个 TCP 连接上完成，此连接可以承载任意数量的双向数据流
* 每个数据流都有一个唯一的标识符和可选的优先级信息，用于承载双向消息
* 每条消息都是一条逻辑 HTTP 消息（例如请求或响应），包含一个或多个帧
* 帧是最小的通信单位，承载着特定类型的数据，例如 HTTP 标头、消息负载，等等。来自不同数据流的帧可以交错发送，然后在根据每个帧头的数据流标识符重新组装

![图片](https://developers.google.com/web/fundamentals/performance/http2/images/streams_messages_frames01.svg?hl=zh-cn)

简言之，HTTP/2 将 HTTP 协议通信分解为二进制编码帧的交换，这些帧对应着特定数据流中的消息。所有这些都在一个 TCP 连接内复用。这是 HTTP/2 协议所有其他功能和性能优化的基础。

### 请求与响应复用

------

在 HTTP/1.x 中，如果客户端想要发起多个并行请求以提升性能，则必须使用多个 TCP 连接（请参阅[使用多个 TCP 连接](https://hpbn.co/http1x/#using-multiple-tcp-connections)）。这是 HTTP/1.x 交互模型的结果，该模型可以保证每个连接每次只交付一个响应（响应排队）。更糟糕的是，这种模型也会导致队首阻塞，从而造成底层 TCP 连接效率低下。

HTTP/2 中新的二进制分帧层突破了这些限制，实现了完整的请求和响应复用：客户端和服务器可以将 HTTP 消息分解为互不依赖的帧，然后交错发送，最后在另一端把它们重新组装起来。

HTTP/1.x 和 HTTP/2 的数据传输过程如下图所示：

![图片](https://ws4.sinaimg.cn/large/006tNc79ly1fnt8buhulnj319m1947fk.jpg)

![图片](https://developers.google.com/web/fundamentals/performance/http2/images/multiplexing01.svg?hl=zh-cn)

快照捕捉了一个连接内并行的多个数据流。客户端正向服务器传送一个 DATA 帧（数据流5），与此同时，服务器正向客户端发送数据流1和数据流3的一系列帧。因此一个连接上同时有三个并行的数据流。

将 HTTP 消息分解为独立的帧，交错发送，然后在另外一端重新组装是 HTTP/2 最重要的一项增强。事实上，这个机制会在整个网络技术栈中引发一系列的连锁反应，从而带来巨大的性能提升，让我们可以：

* 并行交错发送多个请求，请求之间不影响
* 并行交错发送多个响应，响应之间不影响
* 使用一个连接并行发送多个请求和响应
* 不必再为绕过 HTTP/1.x 限制而做很多工作
* 消除不必要的延迟和提高现有网络容量的利用率，从而减少页面加载时间
* 等等....

HTTP/2 中新的二进制分帧层解决了 HTTP/1.x 队首阻塞问题，也消除了并行处理和发送请求和响应时对多个连接的依赖（要开多个 TCP 连接）。结果应用速度更快、开发更简单、部署成本更低。

###  数据流优先级

------

将 HTTP 消息分解为很多独立的帧后，我们就可以复用多个数据流中的帧，客户端和服务器交错发送和传输这些帧的顺序就成为关键的性能决定因素。为了做到这一点，HTTP/2 标准允许每个数据流都有一个关联的权重和依赖关系：

* 可以向每个数据分配一个介于 1 - 256 之间的整数
* 每个数据流和其他数据流之间可以存在显示依赖关系

数据流依赖关系和权重的组合让客户端可以传递和构建优先级树，表明它倾向于如何接受响应。反过来，服务器可以使用此信息通过控制 CPU、内存和其他资源的分配设定数据流处理的优先级，在资源数据可用之后，带宽分配可以确保将高优先级响应以最优的方式传输至客户端。

![图片](https://ws2.sinaimg.cn/large/006tNc79ly1fnt97ja1u6j31hk0psjv3.jpg)

HTTP/2 内的数据流依赖关系通过将另一个数据流的唯一标识符作为父项引用进行声明；如果忽略标识符，相应数据流将依赖于“根数据流”。声明数据流依赖关系指出，应尽可能向父数据流分配资源，然后再向其他依赖项分配资源。换句话说，“请先处理和传输响应 D，然后再处理和传输响应 C”。

共享相同父项的数据流（即，同级数据流）应按照其权重分配资源。例如，如果数据流 A 的权重为 12，其同级数据流 B 的权重为 4，那么要确定每个数据流应接受资源的比列，请执行以下操作：

1. 将所有权重求和：4 + 12 = 16
2. 将每个数据流权重除以总权重：A = 12 / 16，B = 4 / 16，因此，数据流 A 应该获得得四分之三的可用资源，数据流 B 应获得四分之一的可用资源；数据流 B 获得的资源是数据流 A 所获得资源的三分之一。我们来看一下上图中其他几个动手示例：顺序从左到右：
3. 数据流 A 和数据流 B 都没有制定父依赖项，依赖于显示“根数据流”；A 的权重为 12，B 的权重为 4。因此，根据比例权重：数据流 B 获得的资源数据流是 A 所获资源的三分之一
4. 数据流 D 依赖于根数据流；C 依赖于 D。因此，D 应先于 C 获得完整的资源分配。权重不重要，因为 C 的依赖关系拥有更高的优先级
5. 数据流 D 应优先于 C 获得完整资源分配；C 应优先于 A 和 B 获得完整的资源分配；数据流 B 获得的资源是 A 所获资源的三分之一
6. 数据流 D 应优先于 C 和 E 获得完整的资源分配；E 和 C 应优先于 A 和 B 获得相等的资源分配；A 和 B 应基于其权重获得比例分配。

如上面示例所示，数据流依赖关系和权重的组合明确表达了资源优先级，这是一种用于提升浏览器性能的关键功能，网络中拥有多种资源类型，它们的依赖关系和权重各不相同。不仅如此，HTTP/2 协议还允许客户端随时更新这些优先级，进一步优化了浏览器性能。换句话说，我们可以根据用户互动和其他信号更改依赖关系和重新分配权重。

注：数据流依赖关系和权重表示传输优先级，而不是要求，因此不能保证特定的处理或传输顺序。即，客户端无法强制服务器通过数据流优先级以特定顺序处理数据流。尽管这看起来违反直觉，但却是一种必要行为。我们不希望优先级较高的资源收到阻塞时，还阻止服务器处理优先级较低的资源。

### 每个来源一个连接

------

有了新的分帧机制后，HTTP/2 不再依赖多个 TCP 连接去并行复用数据流；每个数据流都拆分成很多帧，而这些帧可以交错，还可以分别设定优先级。因此，所有 HTTP/2  连接都是永久的，而且仅需要每个来源一个连接，随之带来诸多性能优势。

> SPDY 和 HTTP/2 的杀手级功能是，可以在一个拥塞收到良好控制的通道上进行任意复用。这一功能的重要性和良好运行状况让我吃惊。我喜欢的一个非常不错的指标是连接拆分，这些拆分仅承载一个 HTTP 事务（并因此让该事物承担所有开销）。对于 HTTP/1，我们 74% 的活动连接仅承载一个事务-永久连接并不如我们所有人希望的那般有用。但是在 HTTP/2 中，这一比例锐减至 25%[*（HTTP/2 登陆 Firefox，Patrick McManus）*](http://bitsup.blogspot.co.uk/2015/02/http2-is-live-in-firefox.html)

大多数 HTTP 连接都是短暂而急促的，而 TCP 则针对长时间的批量数据传输进行了优化。通过重用相同连接，HTTP/2  既可以更有效的利用每个 TCP 连接，也可以显著降低整体协议开销。不仅如此，使用更少的连接还可以减少占用的内存和处理空间，可以缩短完整连接路径（即，客户端、可信中介和源服务器之间的路径）这降低了整体运行成本并提高了网络利用率和容量。因此，迁移到 HTTP/2  不仅可以减少网络延迟，还有助于提高通量和运行成本。

注：连接数量的减少对提升 HTTPS 部署的性能来说是一项特别重要的功能：可以减少开销较大的 TLS 连接、提升会话利用率，以及整体上减少所需的客户端和服务器资源。

### 流控制

------

流控制是一种阻止发送方向接受方发送大量数据的机制，以免超出后者的需求或处理能力：发送方可能非常忙、处于较高负荷之下，也可能仅仅希望为特定的数据流分配固定量的资源。例如，客户端可能请求了一个具有较高优先级的视频流，但是用户已经暂停视频，客户端希望暂停或者限制从服务器的传输，以免提取和缓冲不必要的数据。再比如，一个代理服务器可能具有较快的下游连接和较慢的上游连接，并且也希望调节下游连接传输数据的速度以匹配上游连接速度来控制其资源利用，等等。

上述要求会让你想到 TCP 的流控制吗？您应当想到这一点；因为问题基本相同（请参阅[流控制](https://hpbn.co/building-blocks-of-tcp/#flow-control)）。不过，由于  HTTP/2  数据流在一个 TCP 连接内复用，TCP 流控制既不够精细，也无法提供必要的应用级 API 来调节各个数据流的传输。为了解决这一问题， HTTP/2  提供了一组简单的构建块，这些构建块允许客户端和服务器实现自己的数据流和连接级流控制：

* 流控制具有方向性。每个接受方都可以根据自身需要选择为每个数据流和整个连接设置任意的窗口大小。
* 流控制基于信用。每个接受方都可以公布其初始连接和数据流流控制窗口（以字节为单位），每当发送方发出 DATA 帧时都会减小，在接受方发出 WINDOW_UPDATE 帧时增大。
* 流控制无法停用。建立  HTTP/2  连接后，客户端将与服务器交换 SETTINGS 帧，这会在两个方向上设置流控制窗口。流控制窗口的默认值为 65535 字节，但是接受方可以设置一个较大的最大窗口大小（2^31 - 1）并在接收到任意数据时通过发送 WINDOW_UPDATE 帧来维持这一大小。
* 流控制为逐跃点控制，而非端到端控制。即，可信中介可以使用它来控制资源使用，以及基于自身条件和启发式算法实现资源的分配机制。

HTTP/2 未指定任何特定的算法来实现流控制。不过，它提供了简单的构建块并推迟了客户端和服务器实现，可以实现自定义策略来调节资源的使用和分配，以及实现新的传输能力，同时提升网络应用的实际性能和感知性能（请参阅[速度、性能和人类感知](https://hpbn.co/primer-on-web-performance/#speed-performance-and-human-perception)）。

例如，应用层流控制允许浏览器仅提取一部分特定的资源，通过将数据流流控制窗口减小为零来停止提取，稍后再恢复。换句话说，它允许浏览器提取图像预览或首次扫描结果，进行显示并允许其他高优先级提取继续，然后在更关键的资源完成加载后恢复提取。

### 服务器推送

------

HTTP/2 新增的另外一个强大的功能是，服务器可以对一个客户端请求发送多个响应。换句话说，除了对最初请求的响应外，服务器还可以向客户端推送额外的资源，如下图，而无需客户端明确地请求。

![图片](https://developers.google.com/web/fundamentals/performance/http2/images/push01.svg?hl=zh-cn)

注：HTTP/2 打破了严格的请求响应语义，支持一对多和服务器发起的推送工作流，在浏览器内外开启了全新的互动可能性。这是一项使用功能，对我们思考协议，协议用途和使用方式具有重要的长期影响。

为什么在浏览器中需要一种此类机制呢？一个典型的网络应用包含多种资源，客户端需要检查服务器提供的文档才能逐个找到它们。那为什么不让服务器提前推送这些资源，从而减少额外的延迟时间呢？服务器已经知道客户端下一步需要请求什么资源，这时候服务器推送即可派上用场。

事实上，如果你在网页中内联过 CSS、Javascript，或者通过数据 URL 内联过其他资产，那么您已经亲身体验过服务器推送了。对于将资源手动内联到文档中的过程，我们实际上是将资源推送给客户端，而不是等待客户端请求。使用 HTTP/2 ，我们不仅可以实现相同结果，还会获得其他性能优势。推送资源可以进行以下处理：

* 由客户端缓存
* 不同面之间重用
* 与其他资源一起复用
* 由服务器设定优先级
* 被客户端拒绝

**PUSH_PROMISE 101**

所有服务器推送数据流都由 PUSH_PROMISE 发起，表明了服务器向客户端推送所述资源的意图，并且需要先于请求推送资源的响应数据传输。这种传输顺序非常重要：客户端需要了解服务器打算推送哪些资源，以免为这些资源创建重复请求。满足要求的最简单策略是先于父响应（即，DATA 帧）发送所有 PUSH_PROMISE 帧，其中包含所承诺资源的 HTTP 头。

在客户端收到 PUSH_PROMISE 帧后，它就可以根据自身情况选择拒绝数据流（通过 RST_STREAM帧）。（如果资源已位于缓存中，可能会发生这种情况）这是一个相对于 HTTP/1.x 的重要提升。相比之下，使用内联（一种受欢迎的 HTTP/1.x “优化”）等同于“强制推送”：客户端无法选择拒绝、取消或单独处理内联的资源。

使用 HTTP/2，客户端仍然完全掌控服务器推送的使用方式。客户端可以限制并行推送的数据流数量；调整初始的流控制窗口以控制在数据流首次打开时推送的数据量；或完全停用服务器推送。这些优先级在 HTTP/2 连接开始时通过 SETINGS 帧传输，可能随时更新。

推送的每个资源都是一个数据流，与内联资源不同，客户端可以对推送资源逐一复用、设定优先级和处理。浏览器强制执行的唯一安全机制是，推送的资源必须符合原点相同这一政策：服务器对所提供的资源必须有权威性。

### 标头压缩

------

每个 HTTP 传输都承载一组标头，这些标头说明了传输资源及其属性。在 HTTP/1.x 中，此元数据始终以纯文本形式，通常会给每个传输增加 500-800 字节的开销。如果使用 HTTP cookie，增加的开销有时会达上千字节。为了减少此开销和提升性能，HTTP/2  使用 HPACK 压缩格式压缩请求和响应标头元数据，这种格式采用两种简单但是强大的技术：

* 这种格式支持通过静态 Huffman 代码对传输的标头字段进行编码，从而减小了各个传输的大小。
* 这种格式要求客户端和服务器同时维护和更新一个包含之前见过的标头字段的索引列表（换句话说，它可以建立一个共享的压缩上下文），此列表随后会用作参考，对之前传输值进行有效编码。

利用 Huffman 编码，可以在传输时对各个值进行压缩，而利用之前传输值的索引列表，我们可以通过传输索引值的方式对重复值进行编码，索引值可以用于有效查询和重构完整的标头键值对。

![图片](https://developers.google.com/web/fundamentals/performance/http2/images/header_compression01.svg?hl=zh-cn)

作为一种进一步优化方式，HPACK 压缩上下文包含一个静态表和一个动态表：静态表在规范中定义，并提供了一个包含所有连接都可能使用的常用 HTTP 标头字段（例如，有效标头名称）的列表；动态表最初值为空，将根据在特定连接内交换的值进行更新。因此，为之前未见过的值采用静态 Huffman 编码，并替换每一侧静态表或动态表中已存在的索引，可以减小每个请求的大小。

注：在  HTTP/2 中，请求和响应标头字段的定义保持不变，仅有些微小差异：所有的标头字段名称均为小写，请求行现在拆分为各个 :method、:scheme、:authority 和 :path 伪标头字段。

**HPACK 安全性和性能**

早期版本的  HTTP/2 和 SPDY 都使用 zlib (带有一个自定义字典) 压缩所有 HTTP 标头。这种方式可以将所传输标头数据的大小减小  85%-88%，显著减少了页面加载时间延迟：

> 在宽带较低的 DSL 链路中，上行链路速度仅有 375 Kbps，仅压缩请求标头就显著减少了特定网站（即，发出大量资源请求的网站）的页面加载时间。我们发现，仅仅由于标头压缩，页面加载时间就少了 45-1142 毫秒。

然而，2012 年夏天，出现了针对 TLS 和 SPDY 压缩算法的“犯罪”安全攻击，此攻击会导致会话被劫持。于是，zlib 算法被 HPACK 代替，后者经过专门设计，可以解决发现的安全问题、实现起来也更高效简单，当然，可以对 HTTP 标头元数据进行良好压缩。

如需了解有关 HPACK 压缩算法的完整详情，请参阅 <https://tools.ietf.org/html/draft-ietf-httpbis-header-compression>。

### 深入阅读

- [“HTTP/2” 已经粉墨登场，我们一起优化性能吧！”](https://docs.google.com/presentation/d/1r7QXGYOLCh4fcUq0jDdDwKJWNqWK1o4xMtYpKZCJYjM/edit?hl=zh-cn#slide=id.p19)
